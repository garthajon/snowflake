{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "wygc73jaw3vwgvs2zuhd",
   "authorId": "1636540973752",
   "authorName": "GARTHJON",
   "authorEmail": "garth.jones@nhs.net",
   "sessionId": "c191deb7-ed23-4159-9149-33afb14003fc",
   "lastEditTime": 1746120213914
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "import_lib",
    "codeCollapsed": false
   },
   "source": "#this integration is being created to run the kaggle diamond dataset machine learning example (dataset here in kaggle):\n#https://www.kaggle.com/datasets/shivam2503/diamonds?resource=download\n#this notenook is based on a training session which was run\n#by Snowflake SME (subject matter expert) Martin Thorup\n# who was teaching the capablities of Snowpark\nfrom snowflake.ml.registry import Registry\n# Snowpark for Python\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark.types import DecimalType\n\nimport numpy as np\n# Override np.float_ with np.float64\nnp.float_ = np.float64\n\n# Snowpark ML\nimport snowflake.ml.modeling.preprocessing as snowml\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.metrics.correlation import correlation\n\n# Data science libs\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport joblib\n\n#warning suppression\nimport warnings; warnings.simplefilter('ignore')\n\n\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8f6d73b2-a686-4011-a758-0fda46c61bfd",
   "metadata": {
    "language": "python",
    "name": "establish_connection"
   },
   "outputs": [],
   "source": "# Get active session (current snowflake session)\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# add a query tag to the session \nsession.query_tag = {\"origin\":\"sf_sit-is\",\"name\":\"e2e_ml_snowparkpython\", \"version\":{\"major\":1,\"minor\":0}}\n\n# Set session context\nsession.use_role(\"ACCOUNTADMIN\")\n\n# get current solution prefix from warehouse name\nsolution_prefix = session.get_current_warehouse()\n#.strip(\"_\").split(\"_DS_WH\")[0]\n\n# Get the current role, warehouse, and database/schema\nprint(f\"Current role: {session.get_current_role()} | Current warehouse: {session.get_current_warehouse()} | DB SCHEMA: {session.sql('select current_database(), current_schema()').collect()}\")\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7cc5dc76-7614-4080-a967-6c6040b2bb89",
   "metadata": {
    "language": "python",
    "name": "load_data"
   },
   "outputs": [],
   "source": "# Data Loading\ndiamonds_df = session.table('DIAMONDS')\ndiamonds_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aca79fa9-b4e9-42ae-adfa-f21487ce0f49",
   "metadata": {
    "language": "python",
    "name": "strip_double_quotes_from_column_name"
   },
   "outputs": [],
   "source": "#strip double quotes from column names\n\n# Function to strip double quotes from column names\ndef strip_double_quotes_from_column_names(df):\n    new_columns = [col.replace('\"', '') for col in df.columns]\n    return df.to_df(*new_columns)\n\n# Apply the function to the DataFrame\ndiamonds_df = strip_double_quotes_from_column_names(diamonds_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1dd2c31-dcde-479b-8359-daf0575e13bc",
   "metadata": {
    "language": "python",
    "name": "minmax_scaler"
   },
   "outputs": [],
   "source": "# Normalize the CARAT column\n\nsnowml_mms = snowml.MinMaxScaler(input_cols=['CARAT'], output_cols=['CARAT_NORM'])\nnormalized_diamonds_df = snowml_mms.fit(diamonds_df).transform(diamonds_df)\nnew_col = normalized_diamonds_df.col(\"CARAT_NORM\").cast(DecimalType(7,6))\nnormalized_diamonds_df.withColumn(\"CARAT_NORM\", new_col)\nnormalized_diamonds_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b5d270b-44a7-44ba-a283-bd7f898c5ec7",
   "metadata": {
    "language": "python",
    "name": "ordinal_encoder"
   },
   "outputs": [],
   "source": "# Encode CUT and CLARITY preserve ordinal importance\n#define the categories for each of the columns in the encoder (put them in the order you wish them to be numbered)\n# note that 0 is the lowest number in sequence \ncategories = {\n   \"CUT\": np.array([\"Ideal\", \"Premium\", \"Very Good\", \"Good\", \"Fair\"]),\n   \"CLARITY\": np.array([\"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\", \"I2\", \"I3\"]),\n}\n\nsnowml_oe = snowml.OrdinalEncoder(input_cols=[\"CUT\", \"CLARITY\"], output_cols=[\"CUT_OE\", \"CLARITY_OE\"], categories=categories)\n# fit the dataframe to the ordinal encoder and generate the output columns\nord_encoded_diamonds_df = snowml_oe.fit(normalized_diamonds_df).transform(normalized_diamonds_df)\n\n\nprint(\"Result Dataframe:\\n\")\nord_encoded_diamonds_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ecbdd5dc-d6a0-44a9-b7ed-17381f1702b6",
   "metadata": {
    "language": "python",
    "name": "One_Hot_Encoder_Categorical_to_Numerical"
   },
   "outputs": [],
   "source": "\n# Encode categoricals to numeric columns\n# the one hot encoder pivots the categories in the column to individual columns\nsnowml_ohe = snowml.OneHotEncoder(input_cols=[\"CUT\", \"COLOR\", \"CLARITY\"], output_cols=[\"CUT_OHE\", \"COLOR_OHE\", \"CLARITY_OHE\"])\ntransformed_diamonds_df = snowml_ohe.fit(ord_encoded_diamonds_df).transform(ord_encoded_diamonds_df)\ntransformed_diamonds_df\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9148dd0-cd76-417d-9579-95729826f098",
   "metadata": {
    "language": "python",
    "name": "Prepare_Categories_For_Ordinal_Encoding_in_Pipeline"
   },
   "outputs": [],
   "source": "# Categorize all the features for processing\nCATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\nCATEGORICAL_COLUMNS_OE = [\"CUT_OE\", \"COLOR_OE\", \"CLARITY_OE\"] # To store the ordinal encoded columns\nNUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", \"TABLE_\", \"X\", \"Y\", \"Z\"]\n\ncategories = {\n    \"CUT\": np.array([\"Ideal\", \"Premium\", \"Very Good\", \"Good\", \"Fair\"]),\n    'CLARITY': np.array(['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2','I1','I2','I3']),\n    'COLOR': np.array(['D','E','F','G','H','I','J'])\n}\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2081f4f-2aa5-429b-b166-434674dece65",
   "metadata": {
    "language": "python",
    "name": "Preprocessing_pipeline_defined"
   },
   "outputs": [],
   "source": "# Build the pipeline\n# both minmaxscaler and ordinal encoder defined as steps within the pre-processing pipeline\npreprocessing_pipeline = Pipeline(\n    steps=[\n        (\n            \"OE\",\n            snowml.OrdinalEncoder(\n                input_cols=CATEGORICAL_COLUMNS,\n                output_cols=CATEGORICAL_COLUMNS_OE,\n                categories=categories,\n            )\n        ),\n        (\n            \"MMS\",\n            snowml.MinMaxScaler(\n                clip=True,\n                input_cols=NUMERICAL_COLUMNS,\n                output_cols=NUMERICAL_COLUMNS,\n            )\n        ),\n    ]\n)\n\nPIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib'\n\njoblib.dump(preprocessing_pipeline, PIPELINE_FILE) # We are just pickling it locally first\n\ntransformed_diamonds_df = preprocessing_pipeline.fit(diamonds_df).transform(diamonds_df)\ntransformed_diamonds_df\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "389d4c96-d344-400c-a260-298b13810102",
   "metadata": {
    "language": "python",
    "name": "save_file_in_a_dedicated_stage"
   },
   "outputs": [],
   "source": "# create the 'models' stage if it does not exist\n# this code is taken from this notebook:\n#https://github.com/sfc-gh-jgriffith/snowpark-end-to-end-ML-with-hyperparameter-tuning/blob/main/02_snowpark_end_to_end_ml.ipynb\n\nquery = \"\"\"create or replace stage models\n           directory = (enable = true)\n           copy_options = (on_error='skip_file')\"\"\"\nsession.sql(query).collect()\n\n# get current database details and store in variable\ndb=session.get_current_database().strip('\"')\n\n#create the file path to save to using the stage\n# note the squiggly brackets used for the database variable\nfile_path = f\"models\"\nprint(file_path)\n#upload the file from the existing temp location to the models stage\n\n#put file to stage from tempfile to persist\nsession.file.put(PIPELINE_FILE, file_path, overwrite=True)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc2048ab-eacf-44ac-9a55-3a11e283c995",
   "metadata": {
    "language": "python",
    "name": "save_pipeline_in_model_registry"
   },
   "outputs": [],
   "source": "#declare registry\n##registry = Registry(session, database_name=\"DATASCIENCE\", schema_name=\"PUBLIC\")\n# Log the model in the registry\n# Log the model with metadata - make sure the essential metadata is present including \n# sample data\n##registry.log_model(model=preprocessing_pipeline, model_name=\"pre_process_diamond\", version_name=\"v1\",comment=\"My awesome ML model\",metrics={\"score\": 96},sample_input_data=transformed_diamonds_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da3753b0-e5cf-4c99-913b-d64d5bb022f6",
   "metadata": {
    "language": "python",
    "name": "pearsons_correlation_matrix"
   },
   "outputs": [],
   "source": "corr_diamonds_df = correlation(df=transformed_diamonds_df)\ncorr_diamonds_df\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13342fa9-d762-4d14-8a6b-b81bc80010d7",
   "metadata": {
    "language": "python",
    "name": "correlation_heatmap_with_triangle_mask"
   },
   "outputs": [],
   "source": "# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr_diamonds_df, dtype=bool))\n\n# Create a heatmap with the features\nplt.figure(figsize=(7, 7))\nheatmap = sns.heatmap(corr_diamonds_df, mask=mask, cmap=\"YlGnBu\", annot=True, vmin=-1, vmax=1)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5169966b-6db1-4eec-b62c-a226aefbf88a",
   "metadata": {
    "language": "python",
    "name": "plot_CARAT_against_PRICE"
   },
   "outputs": [],
   "source": "# Transform the dataframe from a snowflake df to a pandas df and group by PRICE and CARAT\ncounts = transformed_diamonds_df.to_pandas().groupby(['PRICE', 'CARAT']).size().reset_index(name='Count')\n\n# Plotting\nfig, ax = plt.subplots(figsize=(10, 6))\nscatter = sns.scatterplot(data=counts, x='CARAT', y='PRICE', size='Count', alpha=0.6)\n\n# Customize plot\nax.grid(axis='y')\n#ax.set_xlim([0, 61])\n\n#Move legend and remove spines\nscatter.legend(loc='upper left')\nsns.despine(left=True, bottom=True)\n\n# Show plot\nplt.show()\n",
   "execution_count": null
  }
 ]
}