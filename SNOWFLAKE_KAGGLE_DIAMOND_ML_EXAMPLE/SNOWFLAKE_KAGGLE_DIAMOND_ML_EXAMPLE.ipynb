{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "i2qxuwwy6wbt6ys6xpd3",
   "authorId": "205313753696",
   "authorName": "GARTHJON",
   "authorEmail": "garth.jones@nhs.net",
   "sessionId": "051e7e4b-fc2c-4ffe-bf21-0679860a1a6d",
   "lastEditTime": 1744303877109
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "import_lib",
    "codeCollapsed": false
   },
   "source": "#this integration is being created to run the kaggle diamond dataset machine learning example (dataset here in kaggle):\n#https://www.kaggle.com/datasets/shivam2503/diamonds?resource=download\n#this notenook is based on a training session which was run\n#by Snowflake SME (subject matter expert) Martin Thorup\n# who was teaching the capablities of Snowpark\n\n# Snowpark for Python\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark.types import DecimalType\n\nimport numpy as np\n# Override np.float_ with np.float64\nnp.float_ = np.float64\n\n# Snowpark ML\nimport snowflake.ml.modeling.preprocessing as snowml\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.metrics.correlation import correlation\n\n# Data science libs\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport joblib\n\n#warning suppression\nimport warnings; warnings.simplefilter('ignore')\n\n\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8f6d73b2-a686-4011-a758-0fda46c61bfd",
   "metadata": {
    "language": "python",
    "name": "establish_connection"
   },
   "outputs": [],
   "source": "# Get active session (current snowflake session)\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# add a query tag to the session \nsession.query_tag = {\"origin\":\"sf_sit-is\",\"name\":\"e2e_ml_snowparkpython\", \"version\":{\"major\":1,\"minor\":0}}\n\n# Set session context\nsession.use_role(\"ACCOUNTADMIN\")\n\n# get current solution prefix from warehouse name\nsolution_prefix = session.get_current_warehouse()\n#.strip(\"_\").split(\"_DS_WH\")[0]\n\n# Get the current role, warehouse, and database/schema\nprint(f\"Current role: {session.get_current_role()} | Current warehouse: {session.get_current_warehouse()} | DB SCHEMA: {session.sql('select current_database(), current_schema()').collect()}\")\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7cc5dc76-7614-4080-a967-6c6040b2bb89",
   "metadata": {
    "language": "python",
    "name": "load_date"
   },
   "outputs": [],
   "source": "# Data Loading\ndiamonds_df = session.table('DIAMONDS')\ndiamonds_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1dd2c31-dcde-479b-8359-daf0575e13bc",
   "metadata": {
    "language": "python",
    "name": "minmax_scaler"
   },
   "outputs": [],
   "source": "# Normalize the CARAT column\n\nsnowml_mms = snowml.MinMaxScaler(input_cols=['CARAT'], output_cols=['CARAT_NORM'])\nnormalized_diamonds_df = snowml_mms.fit(diamonds_df).transform(diamonds_df)\nnew_col = normalized_diamonds_df.col(\"CARAT_NORM\").cast(DecimalType(7,6))\nnormalized_diamonds_df.withColumn(\"CARAT_NORM\", new_col)\nnormalized_diamonds_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b5d270b-44a7-44ba-a283-bd7f898c5ec7",
   "metadata": {
    "language": "python",
    "name": "ordinal_encoder"
   },
   "outputs": [],
   "source": "# Encode CUT and CLARITY preserve ordinal importance\n#define the categories for each of the columns in the encoder (put them in the order you wish them to be numbered)\n# note that 0 is the lowest number in sequence \ncategories = {\n   \"CUT\": np.array([\"Ideal\", \"Premium\", \"Very Good\", \"Good\", \"Fair\"]),\n   \"CLARITY\": np.array([\"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\", \"I2\", \"I3\"]),\n}\n\nsnowml_oe = snowml.OrdinalEncoder(input_cols=[\"CUT\", \"CLARITY\"], output_cols=[\"CUT_OE\", \"CLARITY_OE\"], categories=categories)\n# fit the dataframe to the ordinal encoder and generate the output columns\nord_encoded_diamonds_df = snowml_oe.fit(normalized_diamonds_df).transform(normalized_diamonds_df)\n\n\nprint(\"Result Dataframe:\\n\")\nord_encoded_diamonds_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ecbdd5dc-d6a0-44a9-b7ed-17381f1702b6",
   "metadata": {
    "language": "python",
    "name": "One_Hot_Encoder_Categorical_to_Numerical"
   },
   "outputs": [],
   "source": "\n# Encode categoricals to numeric columns\n# the one hot encoder pivots the categories in the column to individual columns\nsnowml_ohe = snowml.OneHotEncoder(input_cols=[\"CUT\", \"COLOR\", \"CLARITY\"], output_cols=[\"CUT_OHE\", \"COLOR_OHE\", \"CLARITY_OHE\"])\ntransformed_diamonds_df = snowml_ohe.fit(ord_encoded_diamonds_df).transform(ord_encoded_diamonds_df)\ntransformed_diamonds_df\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9148dd0-cd76-417d-9579-95729826f098",
   "metadata": {
    "language": "python",
    "name": "Prepare_Categories_For_Ordinal_Encoding_in_Pipeline"
   },
   "outputs": [],
   "source": "# Categorize all the features for processing\nCATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\nCATEGORICAL_COLUMNS_OE = [\"CUT_OE\", \"COLOR_OE\", \"CLARITY_OE\"] # To store the ordinal encoded columns\nNUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", '\"table\"', \"X\", \"Y\", \"Z\"]\n\ncategories = {\n    \"CUT\": np.array([\"Ideal\", \"Premium\", \"Very Good\", \"Good\", \"Fair\"]),\n    'CLARITY': np.array(['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2','I1','I2','I3']),\n    'COLOR': np.array(['D','E','F','G','H','I','J'])\n}\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2081f4f-2aa5-429b-b166-434674dece65",
   "metadata": {
    "language": "python",
    "name": "Preprocessing_pipeline_defined"
   },
   "outputs": [],
   "source": "# Build the pipeline\n# both minmaxscaler and ordinal encoder defined as steps within the pre-processing pipeline\npreprocessing_pipeline = Pipeline(\n    steps=[\n        (\n            \"OE\",\n            snowml.OrdinalEncoder(\n                input_cols=CATEGORICAL_COLUMNS,\n                output_cols=CATEGORICAL_COLUMNS_OE,\n                categories=categories,\n            )\n        ),\n        (\n            \"MMS\",\n            snowml.MinMaxScaler(\n                clip=True,\n                input_cols=NUMERICAL_COLUMNS,\n                output_cols=NUMERICAL_COLUMNS,\n            )\n        ),\n    ]\n)\n\nPIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib'\n\njoblib.dump(preprocessing_pipeline, PIPELINE_FILE) # We are just pickling it locally first\n\ntransformed_diamonds_df = preprocessing_pipeline.fit(diamonds_df).transform(diamonds_df)\ntransformed_diamonds_df\n\n",
   "execution_count": null
  }
 ]
}